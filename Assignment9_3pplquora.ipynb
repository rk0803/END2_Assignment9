{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment9_3pplquora.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27S03zbAAPu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSQEcla0Ad0E"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "#!pip install spacy --upgrade"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blRsAVWGqkj1"
      },
      "source": [
        "Since in this assignment, we are only working on English, spacy for english only is needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGS-Zzs2Aglb",
        "outputId": "0dd4fe00-6b50-45b3-86f5-d964d0c827fb"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKK9oA7OArZK"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPubajj7A0pY"
      },
      "source": [
        "def tokenize_n(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)] #[::-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztK5PjShBN_M"
      },
      "source": [
        "QUE1 = Field(tokenize = tokenize_n,\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "QUE2 = Field(tokenize = tokenize_n, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN1U1mDgc2Ng"
      },
      "source": [
        "fields = [('que1', QUE1),('que2',QUE2)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQEHi3hX84Rn"
      },
      "source": [
        "from  torchtext.legacy import data\n",
        "import pandas as pd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmbQa_eaLwFL",
        "outputId": "616f505d-87ab-46a5-fb5b-2f4b240637a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNfqCjUXGZYo"
      },
      "source": [
        "Only those question pairs have to be selected for which duplicate is true. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDmFNCgEGZjv"
      },
      "source": [
        "df=(pd.read_csv('/content/drive/MyDrive/quora_duplicate_questions.tsv',sep='\\t',\n",
        "               header=0,lineterminator='\\n',dtype=pd.StringDtype(),encoding = \"ISO-8859-1\",\n",
        "               names= ['id','qid1','qid2','question1','question2','is_duplicate'],\n",
        "               usecols = ['question1','question2','is_duplicate']))[lambda x: x['is_duplicate'] =='1']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNzcW0nNGsdO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReVRJN6BB_5h"
      },
      "source": [
        "## Overview of the Question Pair Dataset from Quora\n",
        "\n",
        "The file \"quora_duplicate_questions.tsv\" contains the questions-question pairs. The first line of the file contains \n",
        "column names for the tab-separated data fields in the file, which are:\n",
        "\n",
        "id qid1 qid2 question1 question2 is_duplicate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5L0NfgErGAZ"
      },
      "source": [
        "Since we are only focussing on the text part of the dataset, which is question1 and question2, I am only picking up these two columns along with is_duplicate to select only those rows for which is_duplicate is true."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FTKugJ4Hbtm"
      },
      "source": [
        "So here is number of samples which get selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRQUI4tD8ZoY",
        "outputId": "52678065-f78a-48a7-cf85-042a23f80e3b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149263, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEmuYaBfHiD9"
      },
      "source": [
        "Some idea of what the data looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JlJ5MWGm8cWs",
        "outputId": "227cd245-40b7-4d79-9e68-a482d6bc9b82"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question1  ... is_duplicate\n",
              "5   Astrology: I am a Capricorn Sun Cap moon and c...  ...            1\n",
              "7                      How can I be a good geologist?  ...            1\n",
              "11        How do I read and find my YouTube comments?  ...            1\n",
              "12               What can make Physics easy to learn?  ...            1\n",
              "13        What was your first sexual experience like?  ...            1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQ5cqsYHm9R"
      },
      "source": [
        "The first column values which are treated as index now do not have a running number. So needed to reset the index values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te481LCl9Ehc"
      },
      "source": [
        "df=df.reset_index(drop=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aCq1-0zIUAx"
      },
      "source": [
        "Another glimpse of the final data with correct indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-f7QbihX9OJx",
        "outputId": "08601ba0-2a1b-498d-d71b-0f32f2848103"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... is_duplicate\n",
              "0  Astrology: I am a Capricorn Sun Cap moon and c...  ...            1\n",
              "1                     How can I be a good geologist?  ...            1\n",
              "2        How do I read and find my YouTube comments?  ...            1\n",
              "3               What can make Physics easy to learn?  ...            1\n",
              "4        What was your first sexual experience like?  ...            1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRW_bwxNwRd8"
      },
      "source": [
        "Lets first create the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XDD-fHDnSJ6"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([str(df.question1[i]),str(df.question2[i])], fields) for i in range(df.shape[0])]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wMaHWHAIpWG"
      },
      "source": [
        "Now create the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT69FDkhtCV4"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "QQDataset=data.Dataset(example,fields)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training  and test sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train_set, test_set) = QQDataset.split(split_ratio=[0.70, 0.30], random_state=random.seed(SEED))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3cCTrkoB7fu",
        "outputId": "d17349df-cf0a-4dd7-b89d-4822172e003b"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_set.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_set.examples)}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 104484\n",
            "Number of testing examples: 44779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3qVJbpK_2L"
      },
      "source": [
        "QUE1.build_vocab(train_set, min_freq = 2)\n",
        "QUE2.build_vocab(train_set, min_freq = 2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy0xQVgdLBkm",
        "outputId": "9bb42da2-15e6-44ca-d00b-15c173a11618"
      },
      "source": [
        "print(f\"Unique tokens in source  vocabulary: {len(QUE1.vocab)}\")\n",
        "print(f\"Unique tokens in target vocabulary: {len(QUE2.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source  vocabulary: 14579\n",
            "Unique tokens in target vocabulary: 14533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_59ly4LC4T"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0GNSQSCLEOB"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator,  test_iterator = BucketIterator.splits(\n",
        "    (train_set, test_set), sort_key = lambda x: len(x.que1),\n",
        "    sort_within_batch=True,\n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcev-6BmwLxf"
      },
      "source": [
        "#Perplexity\n",
        "In the context of Natural Language Processing, perplexity is one way to evaluate language models.  is not just enough to produce text; we also need a way to measure the quality of the produced text. One such way is to measure how surprised or **perplexed** the RNN was to see the output given the input. That is, if the cross-entropy loss for an input $x_i$ and its corresponding output $y_i$ is $loss(x_i,y_i)$ , then the perplexity would be as follows:\n",
        "\n",
        "$P(x_i,y_i)=e^{loss(x_i,y_i)}$ </br>\n",
        "Using this, we can compute the average perplexity for a training dataset of size M as:\n",
        "$PPL(Dataset_{train})=\\frac{1}{M}\\sum_{i}^{M} P(x_i,y_i)$\n",
        "\n",
        "Question now is what is cross entropy? </br>\n",
        "Lets first understand the definition of entropy given by Shannon. </br>\n",
        "Shannon's Entropy is defined as $E(p)=-\\sum_{i=1}^np(x_i)log_bp(x_i)$ </br>\n",
        "  where $b$ is the base of logarithm used, $n$ is the number of states, and $p(x_i)$ is the probability of system being in state $i$, and $\\sum_{i=1}^n p(x_i)=1.\n",
        "\n",
        "So,  Shannon entropy tells us that the  if a system can be in four possible states,and we know the probability of the system being in any one of the states, then for an infintely long sequence of states, how much minimum memory do we need to store the state of the system.\n",
        "\n",
        "Now Lets look at cross entropy.</br>\n",
        "As the word 'cross' implies, we have two different distributions, say $p$ and $q$, then cross entropy $CE(p,q) = -\\sum_{i=1}^np(x_i)log_bq(x_i)$.</br>\n",
        "So, lets say we have two different systems say $S1$ and $S2$, with two different probability distributions $p$ and $q$. Then cross entropy tells us, for an infinitely large sequence of states, drawn from system $S1$ with probability distribution $p$ and from system $S2$, with probability distribution $q$, how much minimum memory do we need on average to store the states. </br>\n",
        "$E(p)$ will always be less than cross entropy. If $p=q$, CE(p,q)$ will be equal to $E(p)$, and will be at its minimum value.</br>\n",
        "\n",
        "Now lets look at Perplexity.</br>\n",
        "Preplexity is defined with cross entropy as :</br>\n",
        "$PPL(p)=b^{E(p)}$ </br>\n",
        "But what is the pupose of Perplexity in language modeling?</br>\n",
        "If we take M different sentences in the dataset, then these M different sequences represent $m$ different possible states (Some of them same). Now we are building the language model, the original system has states distributed with probability $p$, which have no way to know. We can only estimate that probability distribution by, say, $q$. Then the cross_entropy is CE(p,q), which we also call as cross entropy loss. So for each sequence of states (i.e. sentences), we can write that as $loss(x_i,y_i)=CE(p(x_i),q(y_i))$, where $x_i$ comes from the original system $S1$ and $y_i$ comes from the system $S2$ we are trying to model.</br>\n",
        "\n",
        "If the language model (the one we are bulding) is of extremely low quality, and the words in the sentence are guessed randomly, with each word chosen in equally likely manner, then $q(w_i|w_1,w_2...w_{i-1})=\\frac{1}{m}$, log of this number will be very high ($m$ being very large, making $\\frac{1}{m}$ very small), and hence CE will be very high, leading to high perplexity.\n",
        "\n",
        "But if a model is better, and has actually learned something, then the probability $q$ of a valid sentence like \"I like apples\" is very high (hence log of that very small, hence small preplexity), as compared to an invalid sentence like \" apple fly state\".\n",
        "\n",
        "So as the model learns with each epoch, loss reduces and so is the preplexity. So lower the perplxity better is the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_BWoqrQMsN"
      },
      "source": [
        "import math"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Y4-b1fPekY"
      },
      "source": [
        "#Code for perplexity\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "def prplxity(l):\n",
        "  #loss=criterion(pred, y) #criterion uses the loss function as cross entropy loss.\n",
        "  #l=loss.item()\n",
        "  ppl=math.exp(l)\n",
        "  return ppl\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddiTgU8hLFj1"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKKhHPD2LHX1"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIf8EPxVLJhx"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0_86JVLL-9"
      },
      "source": [
        "INPUT_DIM = len(QUE1.vocab)\n",
        "OUTPUT_DIM = len(QUE2.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBhX5dKuLNar",
        "outputId": "340f16d8-7613-4f0a-a70a-f084ca3390be"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14579, 256)\n",
              "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(14533, 256)\n",
              "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=14533, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSdevJJNLPOt",
        "outputId": "4eb8788b-a5bd-4671-d005-640381e474c1"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 22,264,517 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-CvhZwYLQoT"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO11j3WELR5P"
      },
      "source": [
        "TRG_PAD_IDX = QUE2.vocab.stoi[QUE2.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPJdZMKeJQA1"
      },
      "source": [
        "My Trials to understand the shape of ouputs etc.Pls Ignore next two cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8uHdiFyblfS"
      },
      "source": [
        "b=next(iter(train_iterator))\n",
        "src,trg=b.que1,b.que2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e67d-Q2cbq3d"
      },
      "source": [
        "o=model(src,trg)\n",
        "ou_dim = o.shape[-1]\n",
        "output = o[1:].view(-1, ou_dim)\n",
        "tr = trg[1:].view(-1)\n",
        "optimizer.zero_grad()\n",
        "loss = criterion(output, tr)\n",
        "loss.backward()\n",
        "clip=1      \n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), clip)      \n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HReR1sLS8w"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.que1\n",
        "        trg = batch.que2\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    avloss=epoch_loss / len(iterator)\n",
        "    ppl=prplxity(avloss)      \n",
        "    return avloss,ppl"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfm7iiOmLUhv"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.que1\n",
        "            trg = batch.que2\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "    avloss=epoch_loss / len(iterator)\n",
        "    ppl=prplxity(avloss)      \n",
        "    return avloss,ppl"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXrLres2LWHg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3_9LiZ_KI4P"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6xK1clBSz-f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')\n",
        "import numpy as np"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGdzElxhLXKm",
        "outputId": "87ba2d07-946a-42e3-cf2b-f0cd34d92e01"
      },
      "source": [
        " \n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "global plot_iter, plot_loss_train, plot_loss_val,plot_ppl_train,plot_ppl_test\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss_train = np.zeros((0))\n",
        "plot_loss_val = np.zeros((0))\n",
        "plot_ppl_train = np.zeros((0))\n",
        "plot_ppl_test = np.zeros((0))\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss,train_ppl = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss, test_ppl = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train PPL: {train_ppl:7.3f}')\n",
        "    print(f'\\t Val. Loss: {test_loss:.3f} |  Val. PPL: {test_ppl:7.3f}')\n",
        "    plot_iter = np.append(plot_iter, [epoch])\n",
        "    plot_loss_train = np.append(plot_loss_train, [train_loss])\n",
        "    plot_loss_ = np.append(plot_loss_val, [test_loss])\n",
        "    plot_ppl_train = np.append(plot_ppl_train, [train_ppl])\n",
        "    plot_ppl_test = np.append(plot_ppl_test, [test_ppl])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 4m 22s\n",
            "\t Train Loss: 2.990 | Train PPL:  19.893\n",
            "\t Val. Loss: 3.761 |  Val. PPL:  42.991\n",
            "Epoch: 02 | Time: 4m 22s\n",
            "\t Train Loss: 2.753 | Train PPL:  15.688\n",
            "\t Val. Loss: 3.672 |  Val. PPL:  39.312\n",
            "Epoch: 03 | Time: 4m 22s\n",
            "\t Train Loss: 2.576 | Train PPL:  13.147\n",
            "\t Val. Loss: 3.580 |  Val. PPL:  35.856\n",
            "Epoch: 04 | Time: 4m 21s\n",
            "\t Train Loss: 2.433 | Train PPL:  11.396\n",
            "\t Val. Loss: 3.599 |  Val. PPL:  36.571\n",
            "Epoch: 05 | Time: 4m 20s\n",
            "\t Train Loss: 2.303 | Train PPL:  10.003\n",
            "\t Val. Loss: 3.581 |  Val. PPL:  35.924\n",
            "Epoch: 06 | Time: 4m 21s\n",
            "\t Train Loss: 2.201 | Train PPL:   9.035\n",
            "\t Val. Loss: 3.574 |  Val. PPL:  35.660\n",
            "Epoch: 07 | Time: 4m 20s\n",
            "\t Train Loss: 2.130 | Train PPL:   8.416\n",
            "\t Val. Loss: 3.571 |  Val. PPL:  35.562\n",
            "Epoch: 08 | Time: 4m 20s\n",
            "\t Train Loss: 2.071 | Train PPL:   7.934\n",
            "\t Val. Loss: 3.569 |  Val. PPL:  35.486\n",
            "Epoch: 09 | Time: 4m 20s\n",
            "\t Train Loss: 2.002 | Train PPL:   7.403\n",
            "\t Val. Loss: 3.600 |  Val. PPL:  36.588\n",
            "Epoch: 10 | Time: 4m 20s\n",
            "\t Train Loss: 1.951 | Train PPL:   7.034\n",
            "\t Val. Loss: 3.624 |  Val. PPL:  37.475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "4ZGOEsLgTx_8",
        "outputId": "a7e7746d-94e4-462f-c4ca-01828e4bba59"
      },
      "source": [
        "plt.plot(plot_iter, plot_loss_train, plot_loss_val)\n",
        "display.clear_output(wait=True)\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "amno-Sl4TzGF",
        "outputId": "899d08d2-c0c9-42a6-cc56-7d6272dff29b"
      },
      "source": [
        "plt.plot(plot_iter, plot_ppl_train, plot_ppl_test)\n",
        "display.clear_output(wait=True)\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8URPgZ3jkCH"
      },
      "source": [
        "It can be seen that the train perplexity is gradully reducing with each epoch, as the model is getting better in predicting the text based on what it has seen. So it slowly aligns itself with seen examples and adjusts the probabilites better. So the cross entropy loss reducing leading to a low value for training perplexity. However, the validation perplexity is fluctuating significantly. This is expected because what we are essentially evaluating in the validation perplexity is our model's ability to predict a unseen text based on our learning on training data. Since language can be quite difficult to model, this is a very difficult task, and these fluctuations are natural.\n",
        "\n",
        "Also it can be seen that fluctuations in perplexity are in line with fluctuations in the loss curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjUCB1yYMfIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c520909a-bf7d-40b1-d82b-fd7be3e719ed"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('tut1-model.pt')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c921c627-e974-475a-8940-81d04677034f\", \"tut1-model.pt\", 89061591)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}